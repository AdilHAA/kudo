{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-04-14T19:50:16.593647Z",
     "iopub.status.busy": "2025-04-14T19:50:16.593406Z",
     "iopub.status.idle": "2025-04-14T19:50:26.157100Z",
     "shell.execute_reply": "2025-04-14T19:50:26.156018Z",
     "shell.execute_reply.started": "2025-04-14T19:50:16.593628Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import xgboost as xgb\n",
    "import shap\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Union, Tuple, Optional\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T19:50:26.158321Z",
     "iopub.status.busy": "2025-04-14T19:50:26.157975Z",
     "iopub.status.idle": "2025-04-14T19:50:26.169920Z",
     "shell.execute_reply": "2025-04-14T19:50:26.168860Z",
     "shell.execute_reply.started": "2025-04-14T19:50:26.158305Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# 1. ОЧИСТКА И КОНСОЛИДАЦИЯ ДАННЫХ\n",
    "def load_and_clean_data(file_path):\n",
    "    \"\"\"\n",
    "    Загрузка и очистка данных из CSV файла\n",
    "    \"\"\"\n",
    "    # Загрузка данных\n",
    "    df = pd.read_csv(file_path, parse_dates=['Дата счёта'])\n",
    "    \n",
    "    # Переименование колонок для удобства\n",
    "    column_mapping = {\n",
    "        'Клиент': 'client_id',\n",
    "        'Область': 'region',\n",
    "        'SKU': 'sku',\n",
    "        'Дата счёта': 'invoice_date',\n",
    "        'Количество (шт.)': 'quantity',\n",
    "        'Цена (р.)': 'price',\n",
    "        'Сумма_заказа': 'final_price',\n",
    "        'Группа': 'group',\n",
    "        'Тип': 'type',\n",
    "        'Категория': 'category'\n",
    "    }\n",
    "    \n",
    "    # Применяем переименование для существующих колонок\n",
    "    df.rename(columns={k: v for k, v in column_mapping.items() if k in df.columns}, inplace=True)\n",
    "    \n",
    "    # Обработка числовых колонок\n",
    "    numeric_columns = ['quantity', 'price', 'final_price']\n",
    "    for col in numeric_columns:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "    \n",
    "    # Заполнение пропущенных значений\n",
    "    df.fillna({\n",
    "        'quantity': 0,\n",
    "        'price': 0,\n",
    "        'final_price': 0\n",
    "    }, inplace=True)\n",
    "    \n",
    "    \n",
    "    # Добавление временных компонентов для анализа\n",
    "    if 'invoice_date' in df.columns:\n",
    "        df['year'] = df['invoice_date'].dt.year\n",
    "        df['month'] = df['invoice_date'].dt.month\n",
    "        df['quarter'] = df['invoice_date'].dt.quarter\n",
    "        df['date_key'] = df['invoice_date'].dt.to_period('M').dt.start_time\n",
    "    \n",
    "    return df\n",
    "    \n",
    "def filter_and_deduplicate_canceled_orders(data, time_window='D'):\n",
    "    \"\"\"\n",
    "    Фильтрует отмененные заказы и удаляет дубликаты в рамках заданного временного окна\n",
    "    \n",
    "    Параметры:\n",
    "    data (DataFrame): Датафрейм с данными о заказах\n",
    "    time_window (str): Временное окно для группировки ('D' для дня)\n",
    "    \n",
    "    Возвращает:\n",
    "    DataFrame: Датафрейм с уникальными отмененными заказами\n",
    "    \"\"\"\n",
    "    # Копируем данные, чтобы избежать изменения исходного датафрейма\n",
    "    df = data.copy()\n",
    "    \n",
    "    # Фильтруем отмененные заказы, если есть соответствующая колонка\n",
    "    if 'order_status' in df.columns:\n",
    "        df = df[df['order_status'] == 'canceled']\n",
    "    \n",
    "    # Убедимся, что дата в правильном формате\n",
    "    date_column = 'Дата счёта' if 'Дата счёта' in df.columns else 'invoice_date'\n",
    "    \n",
    "    if not pd.api.types.is_datetime64_any_dtype(df[date_column]):\n",
    "        df[date_column] = pd.to_datetime(df[date_column])\n",
    "    \n",
    "    # Создаем временное окно для группировки\n",
    "    df['time_window'] = df[date_column].dt.floor(time_window)\n",
    "    \n",
    "    # Определяем ключевые колонки для поиска дубликатов\n",
    "    client_col = 'Клиент' if 'Клиент' in df.columns else 'client_id'\n",
    "    sku_col = 'SKU' if 'SKU' in df.columns else 'sku'\n",
    "    quantity_col = 'Количество' if 'Количество' in df.columns else 'quantity'\n",
    "    price_col = 'Цена (р.)' if 'Цена (р.)' in df.columns else 'price'\n",
    "    \n",
    "    # Удаляем дубликаты, оставляя только одно значение для каждой комбинации\n",
    "    deduplicated = df.drop_duplicates(\n",
    "        subset=[client_col, sku_col, quantity_col, price_col, 'time_window']\n",
    "    )\n",
    "    \n",
    "    # Удаляем временную колонку\n",
    "    deduplicated = deduplicated.drop(columns=['time_window'])\n",
    "    \n",
    "    return deduplicated\n",
    "\n",
    "def consolidate_orders(completed_orders_path, uncompleted_orders_path):\n",
    "    \"\"\"\n",
    "    Консолидация выполненных и невыполненных заказов\n",
    "    \"\"\"\n",
    "    # Загрузка и очистка данных\n",
    "    completed = load_and_clean_data(completed_orders_path)\n",
    "    uncompleted = load_and_clean_data(uncompleted_orders_path)\n",
    "    uncompleted = filter_and_deduplicate_canceled_orders(uncompleted)\n",
    "    # Добавление флага статуса заказа\n",
    "    completed['order_status'] = 'completed'\n",
    "    uncompleted['order_status'] = 'uncompleted'\n",
    "    \n",
    "    # Консолидация данных\n",
    "    consolidated = pd.concat([completed, uncompleted], sort=False)\n",
    "    consolidated.fillna(0)\n",
    "    consolidated = consolidated.replace('UNK', 'Unk')\n",
    "    consolidated[consolidated['order_status']=='uncompleted']['final_price'] = 0\n",
    "    return consolidated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T19:50:26.171815Z",
     "iopub.status.busy": "2025-04-14T19:50:26.171564Z",
     "iopub.status.idle": "2025-04-14T19:50:26.199287Z",
     "shell.execute_reply": "2025-04-14T19:50:26.198310Z",
     "shell.execute_reply.started": "2025-04-14T19:50:26.171794Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def prepare_time_series(data, freq='M'):\n",
    "    \"\"\"\n",
    "    Подготовка временных рядов для прогнозирования с сохранением дополнительных агрегированных столбцов \n",
    "    \"\"\"\n",
    "    # Копируем данные, чтобы избежать изменений во входных данных\n",
    "    data_copy = data.copy()\n",
    "    \n",
    "    # Группировка данных по дате\n",
    "    if 'order_status' in data_copy.columns:\n",
    "        data_copy = data_copy[data_copy['order_status'] == 'completed']\n",
    "    \n",
    "    # Убедимся, что у нас есть колонка с датой\n",
    "    if 'date_key' not in data_copy.columns and 'invoice_date' in data_copy.columns:\n",
    "        data_copy['date_key'] = data_copy['invoice_date'].dt.to_period(freq).dt.start_time\n",
    "    \n",
    "    # Добавляем расчет недели месяца\n",
    "    data_copy['week_of_month'] = ((data_copy['invoice_date'].dt.day - 1) // 7) + 1\n",
    "    \n",
    "    # Функция для нахождения наиболее частого значения\n",
    "    def most_frequent(series):\n",
    "        if series.empty:\n",
    "            return None\n",
    "        counts = series.value_counts()\n",
    "        if counts.empty:\n",
    "            return None\n",
    "        return counts.index[0]\n",
    "    \n",
    "    # Создадим словарь агрегаций\n",
    "    agg_dict = {}\n",
    "    \n",
    "    # Добавляем базовые агрегации если соответствующие столбцы существуют\n",
    "    if 'quantity' in data_copy.columns:\n",
    "        agg_dict['quantity'] = 'sum'\n",
    "    if 'final_price' in data_copy.columns:\n",
    "        agg_dict['final_price'] = 'sum'\n",
    "    \n",
    "    # Определяем типы столбцов и добавляем соответствующие агрегации\n",
    "    for col in data_copy.columns:\n",
    "        # Пропускаем уже обработанные столбцы и служебные\n",
    "        if col in agg_dict or col in ['date_key', 'order_status', 'invoice_date', 'Unnamed: 0', \n",
    "                                      'Дата год-месяц', 'client_id', 'sku', 'time_idx', \n",
    "                                      'days_until_holiday', 'is_holiday', 'day_of_week', 'week_of_month']:\n",
    "            continue\n",
    "        if col not in ['usd_rub_Мин', 'usd_rub_Откр', 'usd_rub_Цена', 'inflation_rate']:\n",
    "            # Определяем тип данных и выбираем подходящую агрегацию\n",
    "            dtype = data_copy[col].dtype\n",
    "            if pd.api.types.is_numeric_dtype(dtype):  # Для числовых колонок\n",
    "                agg_dict[col] = 'max'\n",
    "            elif pd.api.types.is_object_dtype(dtype) or pd.api.types.is_categorical_dtype(dtype):  # Для категориальных\n",
    "                agg_dict[col] = most_frequent\n",
    "            elif pd.api.types.is_datetime64_dtype(dtype):  # Для дат\n",
    "                agg_dict[col] = 'max'\n",
    "            elif pd.api.types.is_bool_dtype(dtype):  # Для булевых\n",
    "                agg_dict[col] = 'any'\n",
    "                \n",
    "        elif col == 'usd_rub_Мин':\n",
    "            agg_dict[col] = 'min'\n",
    "            \n",
    "        elif col == 'usd_rub_Откр':\n",
    "            agg_dict[col] = 'mean'\n",
    "\n",
    "        elif col == 'inflation_rate':\n",
    "            agg_dict[col] = 'mean'\n",
    "\n",
    "    # Вычисляем суммарную прибыль по неделям месяца\n",
    "    weekly_sums = data_copy.groupby(['date_key', 'week_of_month'])['final_price'].sum().reset_index()\n",
    "    \n",
    "    # Преобразуем в широкий формат\n",
    "    weekly_pivot = weekly_sums.pivot(\n",
    "        index='date_key', \n",
    "        columns='week_of_month', \n",
    "        values='final_price'\n",
    "    ).fillna(0)\n",
    "    \n",
    "    #переименовываем числовые столбцы в строковые\n",
    "    weekly_pivot = weekly_pivot.rename(columns={\n",
    "        1: 'week_1_revenue',\n",
    "        2: 'week_2_revenue',\n",
    "        3: 'week_3_revenue',\n",
    "        4: 'week_4_revenue',\n",
    "        5: 'week_5_revenue'\n",
    "    })\n",
    "    \n",
    "    # Группировка данных по периоду времени с учетом всех агрегаций\n",
    "    time_series = data_copy.groupby('date_key').agg(agg_dict).reset_index()\n",
    "    time_series = time_series.merge(weekly_pivot, on='date_key', how='left')\n",
    "    time_series = time_series.fillna(0)\n",
    "    \n",
    "    # Установка даты в качестве индекса\n",
    "    time_series.set_index('date_key', inplace=True)\n",
    "    \n",
    "    # Убедимся, что индекс отсортирован\n",
    "    time_series = time_series.sort_index()\n",
    "    return time_series\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T19:50:26.200210Z",
     "iopub.status.busy": "2025-04-14T19:50:26.199968Z",
     "iopub.status.idle": "2025-04-14T19:50:26.221689Z",
     "shell.execute_reply": "2025-04-14T19:50:26.220999Z",
     "shell.execute_reply.started": "2025-04-14T19:50:26.200180Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# 2. РАСЧЕТ ПОТЕНЦИАЛЬНЫХ ПРОДАЖ\n",
    "def calculate_potential_sales(consolidated_data):\n",
    "    \"\"\"\n",
    "    Расчет потенциальных продаж на основе фактических и упущенных заказов\n",
    "    \"\"\"\n",
    "    # Определяем измерения для группировки\n",
    "    dimensions = ['sku', 'year', 'month', 'quarter', 'region', 'group', 'category']\n",
    "    existing_dims = [d for d in dimensions if d in consolidated_data.columns]\n",
    "    \n",
    "    # Расчет фактических продаж\n",
    "    completed_sales = consolidated_data[consolidated_data['order_status'] == 'completed'].groupby(\n",
    "        existing_dims\n",
    "    ).agg({\n",
    "        'quantity': 'sum',\n",
    "        'final_price': 'sum',\n",
    "        'price': 'mean'\n",
    "    }).reset_index()\n",
    "    completed_sales.rename(columns={'final_price': 'actual_revenue'}, inplace=True)\n",
    "    \n",
    "    # Расчет упущенных продаж\n",
    "    lost_sales = consolidated_data[consolidated_data['order_status'] == 'uncompleted'].groupby(\n",
    "        existing_dims\n",
    "    ).agg({\n",
    "        'quantity': 'sum'\n",
    "    }).reset_index()\n",
    "    lost_sales.rename(columns={'quantity': 'lost_quantity'}, inplace=True)\n",
    "    \n",
    "    # Объединение данных\n",
    "    potential_data = pd.merge(\n",
    "        completed_sales, lost_sales, \n",
    "        on=existing_dims, \n",
    "        how='outer'\n",
    "    ).fillna(0)\n",
    "    \n",
    "    # Расчет потенциальной выручки\n",
    "    potential_data['lost_revenue'] = potential_data['lost_quantity'] * potential_data['price']\n",
    "    potential_data['potential_revenue'] = potential_data['actual_revenue'] + potential_data['lost_revenue']\n",
    "    potential_data['loss_ratio'] = potential_data['lost_revenue'] / potential_data['potential_revenue'].replace(0, np.nan)\n",
    "    \n",
    "    return potential_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T19:50:26.222829Z",
     "iopub.status.busy": "2025-04-14T19:50:26.222437Z",
     "iopub.status.idle": "2025-04-14T19:50:26.243915Z",
     "shell.execute_reply": "2025-04-14T19:50:26.242772Z",
     "shell.execute_reply.started": "2025-04-14T19:50:26.222782Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def forecast_by_segment(data, segment_column, periods=12, methods = \"xgboost\"):\n",
    "    \"\"\"\n",
    "    Прогнозирование продаж по сегментам (категория, группа, регион и т.д.)\n",
    "    \"\"\"\n",
    "    # Проверка наличия колонки сегмента\n",
    "    if segment_column not in data.columns:\n",
    "        raise ValueError(f\"Колонка '{segment_column}' не найдена в данных\")\n",
    "    \n",
    "    # Получение уникальных значений сегмента\n",
    "    segments = data[segment_column].unique()\n",
    "    \n",
    "    # Словарь для хранения прогнозов\n",
    "    forecasts = {}\n",
    "    \n",
    "    # Прогнозирование для каждого сегмента\n",
    "    for segment in segments:\n",
    "        segment_data = data[data[segment_column] == segment]\n",
    "        \n",
    "        # Пропускаем сегменты с недостаточным количеством данных\n",
    "        if len(segment_data) < 12:\n",
    "            continue\n",
    "        \n",
    "        # Подготовка временного ряда\n",
    "        ts = prepare_time_series(segment_data)\n",
    "        \n",
    "        # Прогнозирование\n",
    "        forecast = forecast_sales(ts, method = methods, periods=periods)\n",
    "        \n",
    "        # Сохранение результата\n",
    "        forecasts[segment] = forecast\n",
    "    \n",
    "    return forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T19:50:26.244776Z",
     "iopub.status.busy": "2025-04-14T19:50:26.244582Z",
     "iopub.status.idle": "2025-04-14T19:50:26.266642Z",
     "shell.execute_reply": "2025-04-14T19:50:26.265706Z",
     "shell.execute_reply.started": "2025-04-14T19:50:26.244761Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# 4. АНАЛИТИЧЕСКИЕ ОТЧЕТЫ ПО ТРЕНДАМ\n",
    "def generate_trend_report(data, dimensions, metrics, time_unit='month'):\n",
    "    \"\"\"\n",
    "    Генерация аналитических отчетов по трендам по разным измерениям\n",
    "    \"\"\"\n",
    "    # Подготовка данных с временным ключом\n",
    "    if 'date_key' not in data.columns and 'invoice_date' in data.columns:\n",
    "        if time_unit == 'month':\n",
    "            data['date_key'] = data['invoice_date'].dt.to_period('M').dt.start_time\n",
    "        elif time_unit == 'quarter':\n",
    "            data['date_key'] = data['invoice_date'].dt.to_period('Q').dt.start_time\n",
    "        elif time_unit == 'year':\n",
    "            data['date_key'] = data['invoice_date'].dt.to_period('Y').dt.start_time\n",
    "    \n",
    "    # Убедимся, что dimensions и metrics - списки\n",
    "    if isinstance(dimensions, str):\n",
    "        dimensions = [dimensions]\n",
    "    if isinstance(metrics, str):\n",
    "        metrics = [metrics]\n",
    "    \n",
    "    # Словарь для хранения отчетов\n",
    "    reports = {}\n",
    "    \n",
    "    # Генерация отчетов для каждого измерения\n",
    "    for dimension in dimensions:\n",
    "        # Проверка наличия измерения в данных\n",
    "        if dimension not in data.columns:\n",
    "            continue\n",
    "        \n",
    "        # Получение уникальных значений измерения\n",
    "        values = data[dimension].unique()\n",
    "        \n",
    "        # Словарь для хранения трендов по значениям измерения\n",
    "        dimension_trends = {}\n",
    "        \n",
    "        # Анализ тренда для каждого значения измерения\n",
    "        for value in values:\n",
    "            value_data = data[data[dimension] == value]\n",
    "            \n",
    "            # Группировка по времени и расчет метрик\n",
    "            trend = value_data.groupby('date_key').agg({\n",
    "                metric: 'sum' for metric in metrics if metric in data.columns\n",
    "            }).reset_index()\n",
    "            \n",
    "            # Сортировка по времени\n",
    "            trend = trend.sort_values('date_key')\n",
    "            \n",
    "            # Сохранение тренда\n",
    "            dimension_trends[value] = trend\n",
    "        \n",
    "        # Сохранение отчета по измерению\n",
    "        reports[dimension] = dimension_trends\n",
    "    \n",
    "    return reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T19:50:26.267701Z",
     "iopub.status.busy": "2025-04-14T19:50:26.267496Z",
     "iopub.status.idle": "2025-04-14T19:50:26.287983Z",
     "shell.execute_reply": "2025-04-14T19:50:26.287248Z",
     "shell.execute_reply.started": "2025-04-14T19:50:26.267685Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def get_top_performers(data, dimension, metric, n=10, ascending=False):\n",
    "    \"\"\"\n",
    "    Получение топ-N значений по заданному измерению и метрике\n",
    "    \"\"\"\n",
    "    # Проверка наличия колонок\n",
    "    if dimension not in data.columns or metric not in data.columns:\n",
    "        raise ValueError(f\"Колонки '{dimension}' или '{metric}' не найдены в данных\")\n",
    "    \n",
    "    # Группировка и расчет суммы метрики\n",
    "    summary = data.groupby(dimension).agg({\n",
    "        metric: 'sum'\n",
    "    }).reset_index()\n",
    "    \n",
    "    # Сортировка и выбор топ-N\n",
    "    top_n = summary.sort_values(metric, ascending=ascending).head(n)\n",
    "    \n",
    "    return top_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T19:50:26.290180Z",
     "iopub.status.busy": "2025-04-14T19:50:26.289917Z",
     "iopub.status.idle": "2025-04-14T19:50:26.312011Z",
     "shell.execute_reply": "2025-04-14T19:50:26.311323Z",
     "shell.execute_reply.started": "2025-04-14T19:50:26.290156Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_feature_importance(\n",
    "    model: Union[xgb.XGBModel, xgb.Booster],\n",
    "    X: Union[np.ndarray, pd.DataFrame],\n",
    "    importance_type: str = 'gain',\n",
    "    return_shap_values: bool = False,\n",
    "    plot: bool = False,\n",
    "    figsize: Tuple[int, int] = (12, 8)\n",
    ") -> Union[pd.DataFrame, Tuple[pd.DataFrame, np.ndarray]]:\n",
    "    \"\"\"\n",
    "    Получает важность признаков из модели XGBoost, используя как встроенные методы, так и SHAP.\n",
    "    \n",
    "    Параметры:\n",
    "    -----------\n",
    "    model : Union[xgb.XGBModel, xgb.Booster]\n",
    "        Обученная модель XGBoost.\n",
    "    X : Union[np.ndarray, pd.DataFrame]\n",
    "        Данные, на которых модель была обучена или для которых нужно рассчитать важность.\n",
    "    importance_type : str, по умолчанию 'gain'\n",
    "        Тип важности для XGBoost (weight, gain, cover, total_gain, total_cover).\n",
    "    return_shap_values : bool, по умолчанию False\n",
    "        Если True, то возвращает детальные значения SHAP вместе с DataFrame.\n",
    "    plot : bool, по умолчанию False\n",
    "        Если True, то создает визуализацию важности признаков.\n",
    "    figsize : Tuple[int, int], по умолчанию (12, 8)\n",
    "        Размер графика, если plot=True.\n",
    "        \n",
    "    Возвращает:\n",
    "    -----------\n",
    "    pd.DataFrame или Tuple[pd.DataFrame, np.ndarray]\n",
    "        DataFrame с важностью признаков и опционально массив со значениями SHAP.\n",
    "    \"\"\"\n",
    "    # Определяем имена признаков\n",
    "    if isinstance(X, pd.DataFrame):\n",
    "        feature_names = X.columns.tolist()\n",
    "    else:\n",
    "        feature_names = [f'feature_{i}' for i in range(X.shape[1])]\n",
    "    \n",
    "    # Получаем важность признаков из XGBoost\n",
    "    if isinstance(model, xgb.Booster):\n",
    "        xgb_importance_dict = model.get_score(importance_type=importance_type)\n",
    "        # Не все признаки могут быть в словаре, если они не использовались\n",
    "        xgb_importance = np.zeros(len(feature_names))\n",
    "        for feature, importance in xgb_importance_dict.items():\n",
    "            # Предполагаем, что признаки в XGBoost имеют формат 'f0', 'f1', ... или соответствуют именам\n",
    "            if feature.startswith('f') and feature[1:].isdigit():\n",
    "                index = int(feature[1:])\n",
    "                if index < len(xgb_importance):\n",
    "                    xgb_importance[index] = importance\n",
    "            elif feature in feature_names:\n",
    "                index = feature_names.index(feature)\n",
    "                xgb_importance[index] = importance\n",
    "    else:  # для scikit-learn API (XGBRegressor, XGBClassifier)\n",
    "        xgb_importance = model.feature_importances_\n",
    "    \n",
    "    # Создаем DataFrame для XGBoost importance\n",
    "    xgb_importance_df = pd.DataFrame({\n",
    "        'Feature': feature_names,\n",
    "        f'XGB_{importance_type.capitalize()}_Importance': xgb_importance\n",
    "    })\n",
    "    \n",
    "    # Получаем SHAP values\n",
    "    try:\n",
    "        explainer = shap.TreeExplainer(model)\n",
    "        shap_values = explainer.shap_values(X)\n",
    "        \n",
    "        # Обрабатываем разные форматы SHAP values\n",
    "        if isinstance(shap_values, list):  # для мультиклассовой классификации\n",
    "            shap_importance = np.mean([np.abs(sv).mean(axis=0) for sv in shap_values], axis=0)\n",
    "        else:  # для регрессии или бинарной классификации\n",
    "            shap_importance = np.abs(shap_values).mean(axis=0)\n",
    "        \n",
    "        # Создаем DataFrame для SHAP importance\n",
    "        shap_importance_df = pd.DataFrame({\n",
    "            'Feature': feature_names,\n",
    "            'SHAP_Importance': shap_importance\n",
    "        })\n",
    "        \n",
    "        # Объединяем оба DataFrame\n",
    "        combined_importance = pd.merge(shap_importance_df, xgb_importance_df, on='Feature')\n",
    "        \n",
    "        # Сортируем по SHAP importance\n",
    "        combined_importance = combined_importance.sort_values('SHAP_Importance', ascending=False)\n",
    "        \n",
    "        # Визуализация, если требуется\n",
    "        if plot:\n",
    "            plt.figure(figsize=figsize)\n",
    "            \n",
    "            # Создаем два подграфика\n",
    "            fig, (ax1, ax2) = plt.subplots(1, 2, figsize=figsize)\n",
    "            \n",
    "            # Строим график для SHAP importance\n",
    "            combined_importance.sort_values('SHAP_Importance', ascending=True).plot.barh(\n",
    "                x='Feature', y='SHAP_Importance', ax=ax1\n",
    "            )\n",
    "            ax1.set_title('SHAP Importance')\n",
    "            \n",
    "            # Строим график для XGBoost importance\n",
    "            combined_importance.sort_values(f'XGB_{importance_type.capitalize()}_Importance', ascending=True).plot.barh(\n",
    "                x='Feature', y=f'XGB_{importance_type.capitalize()}_Importance', ax=ax2\n",
    "            )\n",
    "            ax2.set_title(f'XGBoost {importance_type.capitalize()} Importance')\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "            # Дополнительно добавляем SHAP summary plot, если требуется visualization\n",
    "            shap.summary_plot(shap_values, X if isinstance(X, pd.DataFrame) else pd.DataFrame(X, columns=feature_names), \n",
    "                             plot_type=\"bar\", show=False)\n",
    "            plt.title('SHAP Feature Importance')\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "        \n",
    "        if return_shap_values:\n",
    "            return combined_importance, shap_values\n",
    "        else:\n",
    "            return combined_importance\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Произошла ошибка при расчете SHAP values: {e}\")\n",
    "        # Если SHAP не удался, возвращаем только XGBoost importance\n",
    "        xgb_importance_df = xgb_importance_df.sort_values(\n",
    "            f'XGB_{importance_type.capitalize()}_Importance', ascending=False\n",
    "        )\n",
    "        return xgb_importance_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T19:50:26.312894Z",
     "iopub.status.busy": "2025-04-14T19:50:26.312736Z",
     "iopub.status.idle": "2025-04-14T19:50:26.489973Z",
     "shell.execute_reply": "2025-04-14T19:50:26.489221Z",
     "shell.execute_reply.started": "2025-04-14T19:50:26.312882Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def forecast_sales(time_series, periods=12, method='prophet', exog_vars=None):\n",
    "    \"\"\"\n",
    "    Прогнозирование продаж на будущий период используя современные методы машинного обучения.\n",
    "    \n",
    "    Параметры:\n",
    "    time_series : DataFrame - временной ряд с колонками 'quantity' и 'final_price'\n",
    "    periods : int - количество периодов для прогноза\n",
    "    method : str - метод прогнозирования ('prophet', 'xgboost', 'average')\n",
    "    exog_vars : DataFrame - экзогенные переменные для моделей (опционально)\n",
    "    \n",
    "    Возвращает:\n",
    "    DataFrame с историческими данными и прогнозом\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from datetime import datetime\n",
    "    import warnings\n",
    "    warnings.filterwarnings('ignore')\n",
    "    \n",
    "    # Проверка наличия данных в временном ряде\n",
    "    if time_series.empty:\n",
    "        print(\"Временной ряд пуст. Прогнозирование невозможно.\")\n",
    "        return pd.DataFrame()  # Возвращаем пустой DataFrame\n",
    "\n",
    "    # Если недостаточно данных для сложных моделей, используем простой метод\n",
    "    if len(time_series) < 12:\n",
    "        print(\"Недостаточно данных для сложных моделей. Используем метод prophet.\")\n",
    "        method = 'prophet'\n",
    "        \n",
    "    # Определение последней даты и создание дат для прогноза\n",
    "    try:\n",
    "        last_date = time_series.index[-1]\n",
    "        forecast_dates = [last_date + pd.DateOffset(months=i+1) for i in range(periods)]\n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка при работе с индексом дат: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # Прогнозирование методом Prophet\n",
    "    if method == 'prophet':\n",
    "        try:\n",
    "            from prophet import Prophet\n",
    "            from sklearn.preprocessing import LabelEncoder\n",
    "            \n",
    "            # Создаем словарь для хранения энкодеров\n",
    "            encoders = {}\n",
    "            \n",
    "            # Подготовка данных для Prophet\n",
    "            df_prophet_quantity = pd.DataFrame({\n",
    "                'ds': time_series.index,\n",
    "                'y': time_series['quantity'].values\n",
    "            })\n",
    "            \n",
    "            df_prophet_revenue = pd.DataFrame({\n",
    "                'ds': time_series.index,\n",
    "                'y': time_series['final_price'].values\n",
    "            })\n",
    "            \n",
    "            # Создание моделей Prophet с логистическим ростом для предотвращения отрицательных значений\n",
    "            model_quantity = Prophet(\n",
    "                growth='logistic',\n",
    "                seasonality_mode='multiplicative',\n",
    "                yearly_seasonality=True, \n",
    "                weekly_seasonality=False, \n",
    "                daily_seasonality=False\n",
    "            )\n",
    "            \n",
    "            model_revenue = Prophet(\n",
    "                growth='logistic',\n",
    "                seasonality_mode='multiplicative',\n",
    "                yearly_seasonality=True, \n",
    "                weekly_seasonality=False, \n",
    "                daily_seasonality=False\n",
    "            )\n",
    "            \n",
    "            # Установка нижней и верхней границы для логистического роста\n",
    "            df_prophet_quantity['floor'] = 0\n",
    "            df_prophet_quantity['cap'] = df_prophet_quantity['y'].max() * 1.5\n",
    "            \n",
    "            df_prophet_revenue['floor'] = 0\n",
    "            df_prophet_revenue['cap'] = df_prophet_revenue['y'].max() * 1.5\n",
    "            \n",
    "            # Обработка числовых и категориальных регрессоров\n",
    "            for col in time_series.columns:\n",
    "                # Пропускаем целевые переменные\n",
    "                if col not in ['quantity', 'final_price']:\n",
    "                    # Преобразуем имя колонки в строку\n",
    "                    col_name = str(col)\n",
    "                    \n",
    "                    # Проверяем, является ли столбец числовым или категориальным\n",
    "                    if pd.api.types.is_numeric_dtype(time_series[col]):\n",
    "                        # Для числовых столбцов добавляем как есть\n",
    "                        df_prophet_quantity[col_name] = time_series[col].values\n",
    "                        df_prophet_revenue[col_name] = time_series[col].values\n",
    "                        model_quantity.add_regressor(col_name)\n",
    "                        model_revenue.add_regressor(col_name)\n",
    "                    elif pd.api.types.is_categorical_dtype(time_series[col]) or pd.api.types.is_object_dtype(time_series[col]):\n",
    "                        # Для категориальных создаем и сохраняем энкодер\n",
    "                        encoders[col] = LabelEncoder()\n",
    "                        # Преобразуем в строки перед кодированием для безопасности\n",
    "                        encoded_values = encoders[col].fit_transform(time_series[col].astype(str))\n",
    "                        df_prophet_quantity[col_name] = encoded_values\n",
    "                        df_prophet_revenue[col_name] = encoded_values\n",
    "                        model_quantity.add_regressor(col_name)\n",
    "                        model_revenue.add_regressor(col_name)\n",
    "    \n",
    "            # Добавление экзогенных переменных\n",
    "            if exog_vars is not None:\n",
    "                for col in exog_vars.columns:\n",
    "                    if col in df_prophet_quantity.columns:\n",
    "                        continue\n",
    "                        \n",
    "                    if pd.api.types.is_numeric_dtype(exog_vars[col]):\n",
    "                        df_prophet_quantity[col] = exog_vars[col].values\n",
    "                        df_prophet_revenue[col] = exog_vars[col].values\n",
    "                    else:\n",
    "                        # Кодирование категориальных переменных\n",
    "                        encoders[col] = LabelEncoder()\n",
    "                        encoded_values = encoders[col].fit_transform(exog_vars[col].astype(str))\n",
    "                        df_prophet_quantity[col] = encoded_values\n",
    "                        df_prophet_revenue[col] = encoded_values\n",
    "                        \n",
    "                    model_quantity.add_regressor(col)\n",
    "                    model_revenue.add_regressor(col)\n",
    "            \n",
    "            # Обучение моделей\n",
    "            model_quantity.fit(df_prophet_quantity)\n",
    "            model_revenue.fit(df_prophet_revenue)\n",
    "            \n",
    "            # Создание фрейма для прогноза\n",
    "            future_quantity = model_quantity.make_future_dataframe(periods=periods, freq='M')\n",
    "            future_revenue = model_revenue.make_future_dataframe(periods=periods, freq='M')\n",
    "            \n",
    "            # Добавляем границы для логистического роста\n",
    "            future_quantity['floor'] = 0\n",
    "            future_quantity['cap'] = df_prophet_quantity['cap'].max()\n",
    "            \n",
    "            future_revenue['floor'] = 0\n",
    "            future_revenue['cap'] = df_prophet_revenue['cap'].max()\n",
    "            \n",
    "            # Создаем копии закодированных признаков\n",
    "            encoded_data = pd.DataFrame(index=time_series.index)\n",
    "            \n",
    "            # Для каждой колонки сохраняем оригинальные и закодированные значения\n",
    "            for col in time_series.columns:\n",
    "                if col not in ['quantity', 'final_price']:\n",
    "                    if col in encoders:\n",
    "                        # Сохраняем закодированные значения\n",
    "                        encoded_data[col] = df_prophet_quantity[col].values\n",
    "                    else:\n",
    "                        # Сохраняем оригинальные значения для числовых признаков\n",
    "                        encoded_data[col] = time_series[col].values\n",
    "            \n",
    "            # Объединяем с будущими датафреймами\n",
    "            future_quantity = pd.merge(\n",
    "                future_quantity, \n",
    "                encoded_data, \n",
    "                left_on='ds', \n",
    "                right_index=True, \n",
    "                how='left'\n",
    "            )\n",
    "            \n",
    "            future_revenue = pd.merge(\n",
    "                future_revenue, \n",
    "                encoded_data, \n",
    "                left_on='ds', \n",
    "                right_index=True, \n",
    "                how='left'\n",
    "            )\n",
    "            \n",
    "            # Определяем, какие строки относятся к будущим датам (те, где будут NaN)\n",
    "            is_future_date = future_quantity['ds'].apply(\n",
    "                lambda x: x not in time_series.index\n",
    "            )\n",
    "            future_indices = future_quantity[is_future_date].index\n",
    "            \n",
    "            # Заполняем пропуски (будущие даты) последними известными значениями\n",
    "            for col in encoded_data.columns:\n",
    "                # Проверяем наличие NaN\n",
    "                if future_quantity[col].isna().any():\n",
    "                    # Берем последнее известное значение\n",
    "                    last_value = encoded_data[col].iloc[-1]\n",
    "                    # Заполняем только для будущих дат\n",
    "                    future_quantity.loc[future_indices, col] = last_value\n",
    "                    future_revenue.loc[future_indices, col] = last_value\n",
    "            \n",
    "            # Проверка наличия NaN перед прогнозированием\n",
    "            nan_columns = future_quantity.columns[future_quantity.isna().any()].tolist()\n",
    "            if nan_columns:\n",
    "                print(f\"Обнаружены NaN в следующих столбцах: {nan_columns}\")\n",
    "                # Автоматическое заполнение пропущенных значений\n",
    "                for col in nan_columns:\n",
    "                    # Используем среднее или моду в зависимости от типа данных\n",
    "                    if pd.api.types.is_numeric_dtype(future_quantity[col]):\n",
    "                        fill_value = future_quantity[col].mean()\n",
    "                    else:\n",
    "                        # Для нечисловых данных используем наиболее частое значение\n",
    "                        non_na_values = future_quantity[col].dropna()\n",
    "                        fill_value = non_na_values.value_counts().idxmax() if not non_na_values.empty else 0\n",
    "                    \n",
    "                    future_quantity[col] = future_quantity[col].fillna(fill_value)\n",
    "                    future_revenue[col] = future_revenue[col].fillna(fill_value)\n",
    "            \n",
    "            # Добавление экзогенных переменных для прогноза\n",
    "            if exog_vars is not None:\n",
    "                for col in exog_vars.columns:\n",
    "                    if col in future_quantity.columns and col not in encoders:\n",
    "                        continue\n",
    "                    \n",
    "                    # Заполняем будущие значения из exog_vars при наличии\n",
    "                    if len(exog_vars) >= periods:\n",
    "                        future_values = exog_vars[col].iloc[-periods:].values\n",
    "                    else:\n",
    "                        future_values = list(exog_vars[col].values) * (periods // len(exog_vars) + 1)\n",
    "                        future_values = future_values[:periods]\n",
    "                    \n",
    "                    # Если колонка категориальная, применяем тот же энкодер\n",
    "                    if col in encoders:\n",
    "                        future_values = encoders[col].transform([str(x) for x in future_values])\n",
    "                    \n",
    "                    # Заполняем только будущие даты (future_indices)\n",
    "                    for i, idx in enumerate(future_indices):\n",
    "                        if i < len(future_values):\n",
    "                            future_quantity.loc[idx, col] = future_values[i]\n",
    "                            future_revenue.loc[idx, col] = future_values[i]\n",
    "            \n",
    "            # Окончательная проверка на NaN перед прогнозом\n",
    "            for df in [future_quantity, future_revenue]:\n",
    "                for col in df.columns:\n",
    "                    if df[col].isna().any():\n",
    "                        print(f\"Предупреждение: колонка {col} все еще содержит NaN\")\n",
    "                        # Заполняем нулями в крайнем случае\n",
    "                        df[col] = df[col].fillna(0)\n",
    "            \n",
    "            # Прогнозирование\n",
    "            forecast_quantity = model_quantity.predict(future_quantity)\n",
    "            forecast_revenue = model_revenue.predict(future_revenue)\n",
    "            \n",
    "            # Создание датафрейма прогноза\n",
    "            forecast_df = pd.DataFrame({\n",
    "                'forecast_quantity':[abs(q) for q in forecast_quantity.tail(periods)['yhat'].values],\n",
    "                'forecast_revenue': [abs(r) for r in forecast_revenue.tail(periods)['yhat'].values],\n",
    "                'quantity_lower': [abs(q)*0.85 for q in forecast_quantity.tail(periods)['yhat_lower'].values],\n",
    "                'quantity_upper': [abs(q)*1.15 for q in forecast_quantity.tail(periods)['yhat_upper'].values],\n",
    "                'revenue_lower': [abs(r)*0.85 for r in forecast_revenue.tail(periods)['yhat_lower'].values],\n",
    "                'revenue_upper': [abs(r)*1.15 for r in forecast_revenue.tail(periods)['yhat_upper'].values]\n",
    "            }, index=forecast_dates)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Ошибка при прогнозировании методом Prophet: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()  # Полный стек ошибки для отладки\n",
    "            return pd.DataFrame()\n",
    "    \n",
    "       # Прогнозирование методом XGBoost\n",
    "    elif method == 'xgboost':\n",
    "        try:\n",
    "            import shap\n",
    "            import xgboost as xgb\n",
    "            import numpy as np\n",
    "            from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "            \n",
    "            # Создаем копию данных для безопасности\n",
    "            data_copy = time_series.copy()\n",
    "            \n",
    "            # Применяем логарифмическое преобразование к целевым переменным\n",
    "            # Добавляем 1, чтобы избежать log(0)\n",
    "            data_copy['quantity_log'] = np.log1p(data_copy['quantity'])\n",
    "            data_copy['final_price_log'] = np.log1p(data_copy['final_price'])\n",
    "            \n",
    "            # Кодирование категориальных переменных\n",
    "            encoders = {}\n",
    "            for col in data_copy.columns:\n",
    "                if col not in ['quantity', 'final_price', 'quantity_log', 'final_price_log']:\n",
    "                    if not pd.api.types.is_numeric_dtype(data_copy[col]):\n",
    "                        encoders[col] = LabelEncoder()\n",
    "                        data_copy[col] = encoders[col].fit_transform(data_copy[col].astype(str))\n",
    "            \n",
    "            # Функция для создания признаков\n",
    "            def create_features(df, label=None, lags=None, ensure_features=None):\n",
    "                df_new = df.copy()\n",
    "                \n",
    "                # Создание лагов\n",
    "                if lags is None:\n",
    "                    lags = [1, 2, 3, 6, 12]\n",
    "                \n",
    "                # Используем логарифмированные значения для лагов\n",
    "                for lag in lags:\n",
    "                    df_new[f'quantity_lag_{lag}'] = df_new['quantity_log'].shift(lag)\n",
    "                    df_new[f'final_price_lag_{lag}'] = df_new['final_price_log'].shift(lag)\n",
    "                \n",
    "                # Добавление временных признаков\n",
    "                df_new['month'] = df_new.index.month\n",
    "                df_new['quarter'] = df_new.index.quarter\n",
    "                df_new['year'] = df_new.index.year\n",
    "                \n",
    "                # Добавление скользящего среднего для логарифмированных значений\n",
    "                for window in [3, 6, 12]:\n",
    "                    df_new[f'quantity_rolling_{window}'] = df_new['quantity_log'].rolling(window=window).mean()\n",
    "                    df_new[f'final_price_rolling_{window}'] = df_new['final_price_log'].rolling(window=window).mean()\n",
    "                \n",
    "                # Добавление экзогенных переменных\n",
    "                if exog_vars is not None:\n",
    "                    for col in exog_vars.columns:\n",
    "                        if not pd.api.types.is_numeric_dtype(exog_vars[col]):\n",
    "                            if col in encoders:\n",
    "                                values = encoders[col].transform(exog_vars[col].astype(str))\n",
    "                            else:\n",
    "                                encoder = LabelEncoder()\n",
    "                                values = encoder.fit_transform(exog_vars[col].astype(str))\n",
    "                                encoders[col] = encoder\n",
    "                            df_new[col] = values\n",
    "                        else:\n",
    "                            df_new[col] = exog_vars[col].values\n",
    "                \n",
    "                # Проверка наличия всех необходимых признаков\n",
    "                if ensure_features is not None:\n",
    "                    for feature in ensure_features:\n",
    "                        if feature not in df_new.columns and feature != label:\n",
    "                            df_new[feature] = 0\n",
    "                \n",
    "                # Заполнение пропусков и получение признаков\n",
    "                df_new = df_new.fillna(df_new.mean())\n",
    "                all_features = [col for col in df_new.columns if col != label and \n",
    "                               col not in ['quantity', 'final_price']]\n",
    "                \n",
    "                if label and label in df_new.columns:\n",
    "                    X = df_new[all_features]\n",
    "                    y = df_new[label]\n",
    "                else:\n",
    "                    X = df_new\n",
    "                    y = None\n",
    "                \n",
    "                return X, y, all_features\n",
    "            \n",
    "            # Создание признаков для обучения с логарифмированными целевыми переменными\n",
    "            X_quantity, y_quantity, feature_list_quantity = create_features(data_copy, label='quantity_log')\n",
    "            X_revenue, y_revenue, feature_list_revenue = create_features(data_copy, label='final_price_log')\n",
    "            \n",
    "            # Преобразование в DataFrame\n",
    "            X_quantity = pd.DataFrame(\n",
    "                X_quantity,\n",
    "                columns=X_quantity.columns,\n",
    "                index=X_quantity.index\n",
    "            )\n",
    "            \n",
    "            X_revenue = pd.DataFrame(\n",
    "                X_revenue,\n",
    "                columns=X_revenue.columns,\n",
    "                index=X_revenue.index\n",
    "            )\n",
    "            \n",
    "            # Обучение моделей с стандартной функцией\n",
    "            model_quantity = xgb.XGBRegressor(\n",
    "                objective='reg:squarederror',  # Стандартная функция потерь\n",
    "                n_estimators=1000,\n",
    "                learning_rate=0.05,\n",
    "                max_depth=5,\n",
    "                subsample=0.8,\n",
    "                colsample_bytree=0.8,\n",
    "                random_state=42\n",
    "            )\n",
    "            \n",
    "            model_revenue = xgb.XGBRegressor(\n",
    "                objective='reg:squarederror',  # Стандартная функция потерь\n",
    "                n_estimators=1000,\n",
    "                learning_rate=0.05,\n",
    "                max_depth=5,\n",
    "                subsample=0.8,\n",
    "                colsample_bytree=0.8,\n",
    "                random_state=42\n",
    "            )\n",
    "            \n",
    "            model_quantity.fit(X_quantity, y_quantity)\n",
    "            model_revenue.fit(X_revenue, y_revenue)\n",
    "            \n",
    "            #Получение feature_importans and SHAP\n",
    "            quantity_importance_df = get_feature_importance(model_quantity, X_quantity)\n",
    "            revenue_importance_df = get_feature_importance(model_revenue, X_revenue)\n",
    "            quantity_importance_df.to_csv('quantity_importance_df.csv')\n",
    "            revenue_importance_df.to_csv('revenue_importance_df.csv')\n",
    "            \n",
    "            # Рекурсивное прогнозирование\n",
    "            forecast_quantity = []\n",
    "            forecast_revenue = []\n",
    "            \n",
    "            # Копируем последние данные для прогноза\n",
    "            future_data = data_copy.copy().iloc[-12:] if len(data_copy) >= 12 else data_copy.copy()\n",
    "            \n",
    "            # Итеративное прогнозирование\n",
    "            for i in range(periods):\n",
    "                next_date = last_date + pd.DateOffset(months=i+1)\n",
    "                \n",
    "                # Создаем признаки для прогноза\n",
    "                X_future_quantity, _, _ = create_features(\n",
    "                    future_data, \n",
    "                    ensure_features=feature_list_quantity\n",
    "                )\n",
    "                \n",
    "                X_future_revenue, _, _ = create_features(\n",
    "                    future_data, \n",
    "                    ensure_features=feature_list_revenue\n",
    "                )\n",
    "                \n",
    "                # Проверка наличия всех признаков\n",
    "                X_future_quantity = X_future_quantity[feature_list_quantity]\n",
    "                X_future_revenue = X_future_revenue[feature_list_revenue]\n",
    "                \n",
    "                # Преобразование в DataFrame\n",
    "                X_future_quantity = pd.DataFrame(\n",
    "                    X_future_quantity,\n",
    "                    columns=X_future_quantity.columns,\n",
    "                    index=X_future_quantity.index\n",
    "                )\n",
    "                \n",
    "                X_future_revenue = pd.DataFrame(\n",
    "                    X_future_revenue,\n",
    "                    columns=X_future_revenue.columns,\n",
    "                    index=X_future_revenue.index\n",
    "                )\n",
    "                \n",
    "                # Прогнозирование в логарифмической шкале\n",
    "                log_quantity_pred = model_quantity.predict(X_future_quantity.iloc[-1:])\n",
    "                log_revenue_pred = model_revenue.predict(X_future_revenue.iloc[-1:])\n",
    "                \n",
    "                # Обратное преобразование из логарифмической шкалы (exp(x)-1)\n",
    "                quantity_pred = np.expm1(log_quantity_pred[0])\n",
    "                revenue_pred = np.expm1(log_revenue_pred[0])\n",
    "\n",
    "                quantity_pred = abs(quantity_pred)\n",
    "                revenue_pred = abs(revenue_pred)\n",
    "                \n",
    "                # Сохранение прогноза после обратного преобразования\n",
    "                forecast_quantity.append(quantity_pred)\n",
    "                forecast_revenue.append(revenue_pred)\n",
    "\n",
    "                forecast_quantity = [abs(q) for q in forecast_quantity]\n",
    "                forecast_revenue = [abs(r) for r in forecast_revenue]\n",
    "                \n",
    "                # Обновление данных - добавляем как обычные, так и логарифмированные значения\n",
    "                new_row = pd.DataFrame({\n",
    "                    'quantity': [quantity_pred],\n",
    "                    'final_price': [revenue_pred],\n",
    "                    'quantity_log': [log_quantity_pred[0]],\n",
    "                    'final_price_log': [log_revenue_pred[0]]\n",
    "                }, index=[next_date])\n",
    "                \n",
    "                # Копируем все остальные признаки из последней строки\n",
    "                for col in future_data.columns:\n",
    "                    if col not in ['quantity', 'final_price', 'quantity_log', 'final_price_log']:\n",
    "                        new_row[col] = future_data[col].iloc[-1]\n",
    "                \n",
    "                # Добавляем строку и удаляем старую\n",
    "                future_data = pd.concat([future_data, new_row])\n",
    "                if len(future_data) > 12:\n",
    "                    future_data = future_data.iloc[1:]\n",
    "            \n",
    "            # Создание датафрейма прогноза\n",
    "            forecast_df = pd.DataFrame({\n",
    "                'forecast_quantity': [abs(q) for q in forecast_quantity],\n",
    "                'forecast_revenue': [abs(r) for r in forecast_revenue],\n",
    "                'quantity_lower': [abs(q * 0.9) for q in forecast_quantity],\n",
    "                'quantity_upper': [abs(q * 1.1) for q in forecast_quantity],\n",
    "                'revenue_lower': [abs(r * 0.9) for r in forecast_revenue],\n",
    "                'revenue_upper': [abs(r * 1.1) for r in forecast_revenue]\n",
    "            }, index=forecast_dates)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Ошибка при прогнозировании методом XGBoost: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            return pd.DataFrame()\n",
    "\n",
    "    \n",
    "    # Прогнозирование средним значением\n",
    "    elif method == 'average':\n",
    "        try:\n",
    "            # Используем среднее за последние периоды\n",
    "            window = min(6, len(time_series))\n",
    "            avg_quantity = time_series['quantity'].tail(window).mean()\n",
    "            avg_revenue = time_series['final_price'].tail(window).mean()\n",
    "            \n",
    "            # Создание датафрейма прогноза\n",
    "            forecast_df = pd.DataFrame({\n",
    "                'forecast_quantity': [avg_quantity] * periods,\n",
    "                'forecast_revenue': [avg_revenue] * periods,\n",
    "                'quantity_lower': [avg_quantity * 0.8] * periods,  # примерный нижний интервал\n",
    "                'quantity_upper': [avg_quantity * 1.2] * periods,  # примерный верхний интервал\n",
    "                'revenue_lower': [avg_revenue * 0.8] * periods,    # примерный нижний интервал\n",
    "                'revenue_upper': [avg_revenue * 1.2] * periods     # примерный верхний интервал\n",
    "            }, index=forecast_dates)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Ошибка при прогнозировании методом среднего: {e}\")\n",
    "            return pd.DataFrame()\n",
    "    \n",
    "    else:\n",
    "        print(f\"Метод прогнозирования '{method}' не поддерживается.\")\n",
    "        print(\"Поддерживаемые методы: 'prophet', 'xgboost', 'average'\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # Объединение исторических данных и прогноза\n",
    "    try:\n",
    "        result = forecast_df\n",
    "        return result\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка при объединении данных: {e}\")\n",
    "        return forecast_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T19:50:26.490936Z",
     "iopub.status.busy": "2025-04-14T19:50:26.490710Z",
     "iopub.status.idle": "2025-04-14T19:51:59.189788Z",
     "shell.execute_reply": "2025-04-14T19:51:59.189133Z",
     "shell.execute_reply.started": "2025-04-14T19:50:26.490920Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Загрузка и консолидация данных...\n",
      "Загружено записей: 3079171\n",
      "\n",
      "2. Расчет потенциальных продаж...\n",
      "Топ-5 SKU по потенциальной выручке:\n",
      "          sku  year  month  quarter  region      group   category  quantity  \\\n",
      "449064  18390  2023      9        3  москва  Пены KUDO  Пены KUDO    167228   \n",
      "440303  18288  2023      9        3  москва  Пены KUDO  Пены KUDO    123427   \n",
      "440204  18288  2023      7        3  москва  Пены KUDO  Пены KUDO    110232   \n",
      "439789  18288  2022      9        3  москва  Пены KUDO  Пены KUDO     95506   \n",
      "453512  18487  2021     10        4  москва  Пены KUDO  Пены KUDO    101259   \n",
      "\n",
      "        actual_revenue       price  lost_quantity  lost_revenue  \\\n",
      "449064    5.696623e+07  351.706740            0.0           0.0   \n",
      "440303    5.480913e+07  453.093842            0.0           0.0   \n",
      "440204    4.482902e+07  418.399277            0.0           0.0   \n",
      "439789    3.980481e+07  428.351792            0.0           0.0   \n",
      "453512    3.887444e+07  393.327854            0.0           0.0   \n",
      "\n",
      "        potential_revenue  loss_ratio  \n",
      "449064       5.696623e+07         0.0  \n",
      "440303       5.480913e+07         0.0  \n",
      "440204       4.482902e+07         0.0  \n",
      "439789       3.980481e+07         0.0  \n",
      "453512       3.887444e+07         0.0  \n",
      "\n",
      "3. Прогнозирование продаж...\n",
      "Прогноз на следующие 12 месяцев:\n",
      "            forecast_quantity  forecast_revenue  quantity_lower  \\\n",
      "2024-07-01          8294685.0      1.532978e+09      7465216.50   \n",
      "2024-08-01          8250032.5      1.530454e+09      7425029.25   \n",
      "2024-09-01          8239433.5      1.527448e+09      7415490.15   \n",
      "2024-10-01          8236542.5      1.522965e+09      7412888.25   \n",
      "2024-11-01          7844193.0      1.519654e+09      7059773.70   \n",
      "2024-12-01          7844193.0      1.519654e+09      7059773.70   \n",
      "2025-01-01          7844193.0      1.519654e+09      7059773.70   \n",
      "2025-02-01          8238082.0      1.435698e+09      7414273.80   \n",
      "2025-03-01          7988583.5      1.498804e+09      7189725.15   \n",
      "2025-04-01          8242923.0      1.519396e+09      7418630.70   \n",
      "2025-05-01          8241052.5      1.519396e+09      7416947.25   \n",
      "2025-06-01          8241052.5      1.524386e+09      7416947.25   \n",
      "\n",
      "            quantity_upper  revenue_lower  revenue_upper  \n",
      "2024-07-01      9124153.50   1.379681e+09   1.686276e+09  \n",
      "2024-08-01      9075035.75   1.377409e+09   1.683500e+09  \n",
      "2024-09-01      9063376.85   1.374703e+09   1.680192e+09  \n",
      "2024-10-01      9060196.75   1.370668e+09   1.675261e+09  \n",
      "2024-11-01      8628612.30   1.367688e+09   1.671619e+09  \n",
      "2024-12-01      8628612.30   1.367688e+09   1.671619e+09  \n",
      "2025-01-01      8628612.30   1.367688e+09   1.671619e+09  \n",
      "2025-02-01      9061890.20   1.292128e+09   1.579268e+09  \n",
      "2025-03-01      8787441.85   1.348924e+09   1.648685e+09  \n",
      "2025-04-01      9067215.30   1.367456e+09   1.671335e+09  \n",
      "2025-05-01      9065157.75   1.367456e+09   1.671335e+09  \n",
      "2025-06-01      9065157.75   1.371947e+09   1.676824e+09  \n",
      "\n",
      "Прогнозирование по категориям продуктов...\n",
      "Недостаточно данных для сложных моделей. Используем метод prophet.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19:51:29 - cmdstanpy - INFO - Chain [1] start processing\n",
      "19:51:31 - cmdstanpy - INFO - Chain [1] done processing\n",
      "19:51:31 - cmdstanpy - INFO - Chain [1] start processing\n",
      "19:51:39 - cmdstanpy - INFO - Chain [1] done processing\n",
      "19:51:40 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Недостаточно данных для сложных моделей. Используем метод prophet.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19:51:41 - cmdstanpy - INFO - Chain [1] done processing\n",
      "19:51:41 - cmdstanpy - INFO - Chain [1] start processing\n",
      "19:51:41 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Прогноз для категории KERRY®:\n",
      "            forecast_quantity  forecast_revenue  quantity_lower  \\\n",
      "2024-07-01        662323.6250       110774208.0    596091.26250   \n",
      "2024-08-01        667207.0625       106597792.0    600486.35625   \n",
      "2024-09-01        659659.6250       111707984.0    593693.66250   \n",
      "2024-10-01        661427.8750       106850000.0    595285.08750   \n",
      "2024-11-01        659524.3750       106945016.0    593571.93750   \n",
      "2024-12-01        659897.5000       106945016.0    593907.75000   \n",
      "2025-01-01        657004.5625       106881800.0    591304.10625   \n",
      "2025-02-01        615516.3125       103506096.0    553964.68125   \n",
      "2025-03-01        642350.8125       101630024.0    578115.73125   \n",
      "2025-04-01        642350.8125       106856112.0    578115.73125   \n",
      "2025-05-01        650076.3750       106856112.0    585068.73750   \n",
      "2025-06-01        654419.3750       106865088.0    588977.43750   \n",
      "\n",
      "            quantity_upper  revenue_lower  revenue_upper  \n",
      "2024-07-01    728555.98750     99696787.2    121851628.8  \n",
      "2024-08-01    733927.76875     95938012.8    117257571.2  \n",
      "2024-09-01    725625.58750    100537185.6    122878782.4  \n",
      "2024-10-01    727570.66250     96165000.0    117535000.0  \n",
      "2024-11-01    725476.81250     96250514.4    117639517.6  \n",
      "2024-12-01    725887.25000     96250514.4    117639517.6  \n",
      "2025-01-01    722705.01875     96193620.0    117569980.0  \n",
      "2025-02-01    677067.94375     93155486.4    113856705.6  \n",
      "2025-03-01    706585.89375     91467021.6    111793026.4  \n",
      "2025-04-01    706585.89375     96170500.8    117541723.2  \n",
      "2025-05-01    715084.01250     96170500.8    117541723.2  \n",
      "2025-06-01    719861.31250     96178579.2    117551596.8  \n",
      "\n",
      "Прогноз для категории AXIOM®:\n",
      "            forecast_quantity  forecast_revenue  quantity_lower  \\\n",
      "2024-07-01       446335.37500       109005032.0   401701.837500   \n",
      "2024-08-01       379898.12500       109009184.0   341908.312500   \n",
      "2024-09-01       382517.12500       100845480.0   344265.412500   \n",
      "2024-10-01       380980.75000       100930344.0   342882.675000   \n",
      "2024-11-01       381354.43750       100820672.0   343218.993750   \n",
      "2024-12-01       381354.43750       100814904.0   343218.993750   \n",
      "2025-01-01       381354.43750       100814904.0   343218.993750   \n",
      "2025-02-01       381817.34375       100912632.0   343635.609375   \n",
      "2025-03-01       381817.34375       100912632.0   343635.609375   \n",
      "2025-04-01       381817.34375       100912632.0   343635.609375   \n",
      "2025-05-01       381817.34375       100936888.0   343635.609375   \n",
      "2025-06-01       381817.34375       100936888.0   343635.609375   \n",
      "\n",
      "            quantity_upper  revenue_lower  revenue_upper  \n",
      "2024-07-01   490968.912500     98104528.8    119905535.2  \n",
      "2024-08-01   417887.937500     98108265.6    119910102.4  \n",
      "2024-09-01   420768.837500     90760932.0    110930028.0  \n",
      "2024-10-01   419078.825000     90837309.6    111023378.4  \n",
      "2024-11-01   419489.881250     90738604.8    110902739.2  \n",
      "2024-12-01   419489.881250     90733413.6    110896394.4  \n",
      "2025-01-01   419489.881250     90733413.6    110896394.4  \n",
      "2025-02-01   419999.078125     90821368.8    111003895.2  \n",
      "2025-03-01   419999.078125     90821368.8    111003895.2  \n",
      "2025-04-01   419999.078125     90821368.8    111003895.2  \n",
      "2025-05-01   419999.078125     90843199.2    111030576.8  \n",
      "2025-06-01   419999.078125     90843199.2    111030576.8  \n",
      "\n",
      "Прогноз для категории Unk:\n",
      "            forecast_quantity  forecast_revenue  quantity_lower  \\\n",
      "2024-07-01        1510827.125       272537920.0    1.359744e+06   \n",
      "2024-08-01        1493439.000       274651904.0    1.344095e+06   \n",
      "2024-09-01        1509507.875       274634592.0    1.358557e+06   \n",
      "2024-10-01        1468302.750       273106176.0    1.321472e+06   \n",
      "2024-11-01        1419305.500       270000576.0    1.277375e+06   \n",
      "2024-12-01        1403642.625       269982560.0    1.263278e+06   \n",
      "2025-01-01        1402730.000       268462592.0    1.262457e+06   \n",
      "2025-02-01        1409912.000       267198272.0    1.268921e+06   \n",
      "2025-03-01        1408259.125       267191136.0    1.267433e+06   \n",
      "2025-04-01        1408259.125       268385296.0    1.267433e+06   \n",
      "2025-05-01        1408425.625       268480544.0    1.267583e+06   \n",
      "2025-06-01        1410076.000       268480544.0    1.269068e+06   \n",
      "\n",
      "            quantity_upper  revenue_lower  revenue_upper  \n",
      "2024-07-01    1.661910e+06    245284128.0    299791712.0  \n",
      "2024-08-01    1.642783e+06    247186713.6    302117094.4  \n",
      "2024-09-01    1.660459e+06    247171132.8    302098051.2  \n",
      "2024-10-01    1.615133e+06    245795558.4    300416793.6  \n",
      "2024-11-01    1.561236e+06    243000518.4    297000633.6  \n",
      "2024-12-01    1.544007e+06    242984304.0    296980816.0  \n",
      "2025-01-01    1.543003e+06    241616332.8    295308851.2  \n",
      "2025-02-01    1.550903e+06    240478444.8    293918099.2  \n",
      "2025-03-01    1.549085e+06    240472022.4    293910249.6  \n",
      "2025-04-01    1.549085e+06    241546766.4    295223825.6  \n",
      "2025-05-01    1.549268e+06    241632489.6    295328598.4  \n",
      "2025-06-01    1.551084e+06    241632489.6    295328598.4  \n",
      "\n",
      "Прогноз для категории KUDO® универсальные ЛКМ:\n",
      "            forecast_quantity  forecast_revenue  quantity_lower  \\\n",
      "2024-07-01         3317049.25       459793984.0     2985344.325   \n",
      "2024-08-01         3276716.50       453649152.0     2949044.850   \n",
      "2024-09-01         3278057.50       452453184.0     2950251.750   \n",
      "2024-10-01         3265124.75       452380704.0     2938612.275   \n",
      "2024-11-01         3041379.50       433314496.0     2737241.550   \n",
      "2024-12-01         2694004.00       403948224.0     2424603.600   \n",
      "2025-01-01         2694004.00       403948224.0     2424603.600   \n",
      "2025-02-01         2890889.50       421966080.0     2601800.550   \n",
      "2025-03-01         2903278.50       422156064.0     2612950.650   \n",
      "2025-04-01         2903278.50       422974944.0     2612950.650   \n",
      "2025-05-01         2903278.50       423194432.0     2612950.650   \n",
      "2025-06-01         2903655.00       423199264.0     2613289.500   \n",
      "\n",
      "            quantity_upper  revenue_lower  revenue_upper  \n",
      "2024-07-01     3648754.175    413814585.6    505773382.4  \n",
      "2024-08-01     3604388.150    408284236.8    499014067.2  \n",
      "2024-09-01     3605863.250    407207865.6    497698502.4  \n",
      "2024-10-01     3591637.225    407142633.6    497618774.4  \n",
      "2024-11-01     3345517.450    389983046.4    476645945.6  \n",
      "2024-12-01     2963404.400    363553401.6    444343046.4  \n",
      "2025-01-01     2963404.400    363553401.6    444343046.4  \n",
      "2025-02-01     3179978.450    379769472.0    464162688.0  \n",
      "2025-03-01     3193606.350    379940457.6    464371670.4  \n",
      "2025-04-01     3193606.350    380677449.6    465272438.4  \n",
      "2025-05-01     3193606.350    380874988.8    465513875.2  \n",
      "2025-06-01     3194020.500    380879337.6    465519190.4  \n",
      "\n",
      "Прогноз для категории Герметики и клеи KUDO:\n",
      "            forecast_quantity  forecast_revenue  quantity_lower  \\\n",
      "2024-07-01       490239.15625        65481500.0   441215.240625   \n",
      "2024-08-01       483848.87500        65311612.0   435463.987500   \n",
      "2024-09-01       495526.21875        65701436.0   445973.596875   \n",
      "2024-10-01       497583.34375        65785576.0   447825.009375   \n",
      "2024-11-01       502851.78125        65766004.0   452566.603125   \n",
      "2024-12-01       502851.78125        65765752.0   452566.603125   \n",
      "2025-01-01       482047.12500        65618028.0   433842.412500   \n",
      "2025-02-01       470018.15625        64623884.0   423016.340625   \n",
      "2025-03-01       482768.50000        64614268.0   434491.650000   \n",
      "2025-04-01       483019.03125        64630048.0   434717.128125   \n",
      "2025-05-01       483878.43750        64642620.0   435490.593750   \n",
      "2025-06-01       483878.43750        64744792.0   435490.593750   \n",
      "\n",
      "            quantity_upper  revenue_lower  revenue_upper  \n",
      "2024-07-01   539263.071875     58933350.0     72029650.0  \n",
      "2024-08-01   532233.762500     58780450.8     71842773.2  \n",
      "2024-09-01   545078.840625     59131292.4     72271579.6  \n",
      "2024-10-01   547341.678125     59207018.4     72364133.6  \n",
      "2024-11-01   553136.959375     59189403.6     72342604.4  \n",
      "2024-12-01   553136.959375     59189176.8     72342327.2  \n",
      "2025-01-01   530251.837500     59056225.2     72179830.8  \n",
      "2025-02-01   517019.971875     58161495.6     71086272.4  \n",
      "2025-03-01   531045.350000     58152841.2     71075694.8  \n",
      "2025-04-01   531320.934375     58167043.2     71093052.8  \n",
      "2025-05-01   532266.281250     58178358.0     71106882.0  \n",
      "2025-06-01   532266.281250     58270312.8     71219271.2  \n",
      "\n",
      "Прогноз для категории Пены KUDO:\n",
      "            forecast_quantity  forecast_revenue  quantity_lower  \\\n",
      "2024-07-01       1.394885e+06       433313664.0    1.255396e+06   \n",
      "2024-08-01       1.383871e+06       428210688.0    1.245484e+06   \n",
      "2024-09-01       1.346551e+06       412431872.0    1.211896e+06   \n",
      "2024-10-01       1.273368e+06       413090848.0    1.146031e+06   \n",
      "2024-11-01       1.273438e+06       410296960.0    1.146094e+06   \n",
      "2024-12-01       1.245302e+06       401634208.0    1.120772e+06   \n",
      "2025-01-01       1.185511e+06       398634880.0    1.066960e+06   \n",
      "2025-02-01       1.133774e+06       360225920.0    1.020396e+06   \n",
      "2025-03-01       1.085654e+06       349961664.0    9.770882e+05   \n",
      "2025-04-01       1.041582e+06       345191136.0    9.374242e+05   \n",
      "2025-05-01       1.069275e+06       347550976.0    9.623473e+05   \n",
      "2025-06-01       1.112910e+06       347793664.0    1.001619e+06   \n",
      "\n",
      "            quantity_upper  revenue_lower  revenue_upper  \n",
      "2024-07-01    1.534373e+06    389982297.6    476645030.4  \n",
      "2024-08-01    1.522258e+06    385389619.2    471031756.8  \n",
      "2024-09-01    1.481207e+06    371188684.8    453675059.2  \n",
      "2024-10-01    1.400705e+06    371781763.2    454399932.8  \n",
      "2024-11-01    1.400782e+06    369267264.0    451326656.0  \n",
      "2024-12-01    1.369832e+06    361470787.2    441797628.8  \n",
      "2025-01-01    1.304062e+06    358771392.0    438498368.0  \n",
      "2025-02-01    1.247151e+06    324203328.0    396248512.0  \n",
      "2025-03-01    1.194219e+06    314965497.6    384957830.4  \n",
      "2025-04-01    1.145741e+06    310672022.4    379710249.6  \n",
      "2025-05-01    1.176202e+06    312795878.4    382306073.6  \n",
      "2025-06-01    1.224200e+06    313014297.6    382573030.4  \n",
      "\n",
      "Прогноз для категории KUDO® автомобильные ЛКМ:\n",
      "            forecast_quantity  forecast_revenue  quantity_lower  \\\n",
      "2024-07-01       470022.65625        81603944.0   423020.390625   \n",
      "2024-08-01       487141.31250        81526160.0   438427.181250   \n",
      "2024-09-01       474700.84375        83846736.0   427230.759375   \n",
      "2024-10-01       483813.81250        81840088.0   435432.431250   \n",
      "2024-11-01       435756.15625        83920176.0   392180.540625   \n",
      "2024-12-01       441601.37500        74990904.0   397441.237500   \n",
      "2025-01-01       395370.40625        74798192.0   355833.365625   \n",
      "2025-02-01       397632.00000        72179832.0   357868.800000   \n",
      "2025-03-01       397334.43750        72256696.0   357600.993750   \n",
      "2025-04-01       392362.81250        72411216.0   353126.531250   \n",
      "2025-05-01       404043.31250        72412320.0   363638.981250   \n",
      "2025-06-01       393602.59375        72411216.0   354242.334375   \n",
      "\n",
      "            quantity_upper  revenue_lower  revenue_upper  \n",
      "2024-07-01   517024.921875     73443549.6     89764338.4  \n",
      "2024-08-01   535855.443750     73373544.0     89678776.0  \n",
      "2024-09-01   522170.928125     75462062.4     92231409.6  \n",
      "2024-10-01   532195.193750     73656079.2     90024096.8  \n",
      "2024-11-01   479331.771875     75528158.4     92312193.6  \n",
      "2024-12-01   485761.512500     67491813.6     82489994.4  \n",
      "2025-01-01   434907.446875     67318372.8     82278011.2  \n",
      "2025-02-01   437395.200000     64961848.8     79397815.2  \n",
      "2025-03-01   437067.881250     65031026.4     79482365.6  \n",
      "2025-04-01   431599.093750     65170094.4     79652337.6  \n",
      "2025-05-01   444447.643750     65171088.0     79653552.0  \n",
      "2025-06-01   432962.853125     65170094.4     79652337.6  \n",
      "\n",
      "Прогноз для категории Монтажная пена KUDO PRORAB:\n",
      "            forecast_quantity  forecast_revenue  quantity_lower  \\\n",
      "2024-07-01       19810.654978      2.761577e+07    16839.056748   \n",
      "2024-08-01       55226.012106      6.573246e+06    46942.110308   \n",
      "2024-09-01       34414.453842      2.079807e+07    29252.285787   \n",
      "2024-10-01       31594.892082      4.830380e+05    26855.658295   \n",
      "2024-11-01       14184.183800      1.796687e+07    12056.556256   \n",
      "2024-12-01       25177.009070      1.162253e+07    21400.457753   \n",
      "2025-01-01         497.262816      1.987657e+07      422.673377   \n",
      "2025-02-01       26235.344725      1.248859e+07    22300.043106   \n",
      "2025-03-01       49971.968134      1.264137e+07    42476.173128   \n",
      "2025-04-01       47651.724048      8.368709e+06    40503.965182   \n",
      "2025-05-01       10139.416779      4.821029e+06     8618.504334   \n",
      "2025-06-01        9089.157149      1.186567e+06     7725.783500   \n",
      "\n",
      "            quantity_upper  revenue_lower  revenue_upper  \n",
      "2024-07-01    22782.253201   2.347341e+07   3.175814e+07  \n",
      "2024-08-01    63509.913897   5.587258e+06   7.559233e+06  \n",
      "2024-09-01    39576.621893   1.767836e+07   2.391779e+07  \n",
      "2024-10-01    36334.125859   4.105825e+05   5.554935e+05  \n",
      "2024-11-01    16311.811339   1.527183e+07   2.066191e+07  \n",
      "2024-12-01    28953.560370   9.879140e+06   1.336592e+07  \n",
      "2025-01-01      571.852260   1.689511e+07   2.285803e+07  \n",
      "2025-02-01    30170.646313   1.061528e+07   1.436190e+07  \n",
      "2025-03-01    57467.763071   1.074515e+07   1.453761e+07  \n",
      "2025-04-01    54799.483007   7.113386e+06   9.624038e+06  \n",
      "2025-05-01    11660.329199   4.097864e+06   5.544199e+06  \n",
      "2025-06-01    10452.530828   1.008579e+06   1.364556e+06  \n",
      "\n",
      "Прогноз для категории Строительная химия KUDO  для производств:\n",
      "            forecast_quantity  forecast_revenue  quantity_lower  \\\n",
      "2024-07-01        8006.731740      81146.667238     6805.721981   \n",
      "2024-08-01         744.665480     134691.750592      632.974901   \n",
      "2024-09-01        8014.604010      90592.348928     6812.733783   \n",
      "2024-10-01       13103.772358      63638.303548    11137.156409   \n",
      "2024-11-01       10413.255446     190557.493748     8852.595719   \n",
      "2024-12-01        7916.050271     142832.422085     6730.046388   \n",
      "2025-01-01        7484.729424      74051.924491     6360.289047   \n",
      "2025-02-01        1674.791750     111655.082924     1424.043350   \n",
      "2025-03-01        4029.234099     108330.907029     3423.423007   \n",
      "2025-04-01        2692.926631     121428.462281     2287.866047   \n",
      "2025-05-01        4396.233337     185730.663067     3734.643773   \n",
      "2025-06-01        1824.217637      68808.073346     1551.547235   \n",
      "\n",
      "            quantity_upper  revenue_lower  revenue_upper  \n",
      "2024-07-01     9207.741500   68974.651315   93318.686719  \n",
      "2024-08-01      856.353346  114487.973430  154895.533476  \n",
      "2024-09-01     9216.341471   77003.481043  104181.222507  \n",
      "2024-10-01    15070.704462   54092.543077   73184.067413  \n",
      "2024-11-01    11973.427205  161973.854879  219141.138971  \n",
      "2024-12-01     9101.522594  121407.544111  164257.305165  \n",
      "2025-01-01     8609.787140   62944.120790   85159.733068  \n",
      "2025-02-01     1925.353323   94906.805164  128403.365717  \n",
      "2025-03-01     4635.505395   92081.254251  124580.562999  \n",
      "2025-04-01     3098.322740  103214.177670  139642.752909  \n",
      "2025-05-01     5058.422514  157871.046303  213590.285561  \n",
      "2025-06-01     2096.509436   58486.846068   79129.305180  \n",
      "\n",
      "4. Аналитические отчеты по трендам...\n",
      "Сгенерированы отчеты по трендам для 3 измерений\n",
      "\n",
      "Топ-10 клиентов по выручке:\n",
      "      client_id   final_price\n",
      "493      148163  4.739415e+09\n",
      "275      143015  3.125042e+09\n",
      "309      143779  1.033830e+09\n",
      "269      142877  8.367017e+08\n",
      "1396     154860  7.320352e+08\n",
      "791      151456  6.983240e+08\n",
      "767      151016  6.467500e+08\n",
      "471      147841  5.641269e+08\n",
      "613      149376  5.461153e+08\n",
      "185      141217  5.364438e+08\n",
      "\n",
      "Топ-10 SKU по количеству:\n",
      "        sku  quantity\n",
      "249    1407   8811372\n",
      "1495  18161   7964236\n",
      "1033  14069   7473318\n",
      "1569  18390   6411958\n",
      "1535  18288   5456171\n",
      "1842  20141   4933926\n",
      "1607  18487   4566056\n",
      "1525  18254   4562134\n",
      "248    1406   4056965\n",
      "1147  14640   3651136\n",
      "\n",
      "Анал из из данных успешно завершен!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ПРИМЕР ИСПОЛЬЗОВАНИЯ КОДА\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Пример использования функций для анализа данных KUDO\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # 1. Загрузка и консолидация данных\n",
    "        print(\"1. Загрузка и консолидация данных...\")\n",
    "        consolidated_data = consolidate_orders('final_df_latest2.csv', 'denied.csv')\n",
    "        print(f\"Загружено записей: {len(consolidated_data)}\")\n",
    "        # 2. Расчет потенциальных продаж\n",
    "        print(\"\\n2. Расчет потенциальных продаж...\")\n",
    "        potential_sales = calculate_potential_sales(consolidated_data)\n",
    "        print(f\"Топ-5 SKU по потенциальной выручке:\")\n",
    "        print(potential_sales.sort_values('potential_revenue', ascending=False).head())\n",
    "        potential_sales.sort_values('potential_revenue', ascending=False).head().to_csv(\"potential_sales.csv\")\n",
    "        # 3. Прогнозирование продаж\n",
    "        print(\"\\n3. Прогнозирование продаж...\")\n",
    "        # Общий прогноз\n",
    "        time_series = prepare_time_series(consolidated_data)\n",
    "        time_series[['quantity','final_price']].to_csv(\"quantity_and_revenue.csv\")\n",
    "        forecast = forecast_sales(time_series, periods=12,method =\"xgboost\")\n",
    "        forecast.tail(12).to_csv(\"main_forecast.csv\")\n",
    "        print(\"Прогноз на следующие 12 месяцев:\")\n",
    "        print(forecast.tail(12))\n",
    "        \n",
    "        #Прогноз по категориям\n",
    "        print(\"\\nПрогнозирование по категориям продуктов...\")\n",
    "        category_forecasts = forecast_by_segment(consolidated_data, 'category', periods=12)\n",
    "        for category, forecast in category_forecasts.items():\n",
    "            print(f\"\\nПрогноз для категории {category}:\")\n",
    "            forecast.to_csv(f\"forecast_for_{category}_category.csv\")\n",
    "            print(forecast.tail(12))\n",
    "        \n",
    "        # 4. Аналитические отчеты\n",
    "        print(\"\\n4. Аналитические отчеты по трендам...\")\n",
    "        # Отчеты по трендам\n",
    "        trend_reports = generate_trend_report(\n",
    "            consolidated_data, \n",
    "            dimensions=['category', 'group', 'region'], \n",
    "            metrics=['quantity', 'final_price']\n",
    "        )\n",
    "        \n",
    "        print(f\"Сгенерированы отчеты по трендам для {len(trend_reports)} измерений\")\n",
    "        \n",
    "        # Топ клиентов и SKU\n",
    "        top_clients = get_top_performers(consolidated_data, 'client_id', 'final_price')\n",
    "        print(\"\\nТоп-10 клиентов по выручке:\")\n",
    "        print(top_clients)\n",
    "        top_clients.to_csv(\"top_clients.csv\")\n",
    "        \n",
    "        top_skus = get_top_performers(consolidated_data, 'sku', 'quantity')\n",
    "        print(\"\\nТоп-10 SKU по количеству:\")\n",
    "        print(top_skus)\n",
    "        top_skus.to_csv(\"top_skus.csv\")\n",
    "        print(\"\\nАнализ из данных успешно завершен!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка при выполнении анализа: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 6940339,
     "sourceId": 11128482,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6998061,
     "sourceId": 11207511,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6998133,
     "sourceId": 11207612,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7123594,
     "sourceId": 11377869,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7137267,
     "sourceId": 11396183,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7137280,
     "sourceId": 11396205,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31012,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
